import re
from pathlib import Path
from pdf2image import convert_from_path
import pytesseract
from PyPDF2 import PdfReader


# ========= UTILIDAD GENERAL PARA OCR Y EXTRACCIN ==========
def extract_text_with_ocr(pdf_path):
    """
    Extrae texto de un PDF combinando extracci贸n directa y OCR.
    """
    text = ""

    # 1锔 Intentar leer texto directamente
    try:
        reader = PdfReader(pdf_path)
        for page in reader.pages:
            text += page.extract_text() or ""
    except Exception as e:
        print(f"Error al leer PDF directamente: {e}")

    # 2锔 Si el texto directo es insuficiente, aplicar OCR
    if not text or len(text.strip()) < 100:
        try:
            images = convert_from_path(pdf_path, dpi=300)
            for img in images:
                text += pytesseract.image_to_string(img, lang="spa")
        except Exception as e:
            print(f"Error al aplicar OCR: {e}")

    return text


# ========= SECCIONES DE LA HOJA DE VIDA ==========
def extract_profile_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'Perfil' del PDF.
    """
    text = extract_text_with_ocr(pdf_path)
    if not text.strip():
        return ""

    start_keyword = "Perfil"
    end_keywords = ["Asistencia a eventos", "Actualizaci贸n profesional"]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()
    section = re.sub(r"[^\w\s.,;:()\-]", "", section)
    section = re.sub(r"\s+", " ", section)

    return section


def extract_experience_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'EXPERIENCIA EN ANEIAP' del PDF.
    """
    text = extract_text_with_ocr(pdf_path)
    start_keyword = "EXPERIENCIA EN ANEIAP"
    end_keywords = ["EVENTOS ORGANIZADOS", "Reconocimientos individuales", "Reconocimientos"]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()
    exclude_lines = [
        "a nivel capitular", "a nivel nacional", "a nivel seccional",
        "reconocimientos individuales", "reconocimientos grupales",
        "trabajo capitular", "trabajo nacional", "nacional 2024"
    ]

    lines = section.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)
        normalized = re.sub(r"\s+", " ", line).lower()
        if normalized and normalized not in exclude_lines:
            cleaned.append(line)

    return "\n".join(cleaned)


def extract_event_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'EVENTOS ORGANIZADOS' del PDF.
    """
    text = extract_text_with_ocr(pdf_path)
    start_keyword = "EVENTOS ORGANIZADOS"
    end_keywords = ["EXPERIENCIA LABORAL", "FIRMA"]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()
    exclude_lines = [
        "a nivel capitular", "a nivel nacional", "a nivel seccional",
        "reconocimientos individuales", "reconocimientos grupales"
    ]

    lines = section.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)
        normalized = re.sub(r"\s+", " ", line).lower()
        if normalized and normalized not in exclude_lines:
            cleaned.append(line)

    return "\n".join(cleaned)


def extract_attendance_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'ASISTENCIA A EVENTOS ANEIAP' del PDF.
    """
    text = extract_text_with_ocr(pdf_path)
    start_keyword = "ASISTENCIA A EVENTOS ANEIAP"
    end_keywords = ["ACTUALIZACIN PROFESIONAL", "EXPERIENCIA EN ANEIAP", "EVENTOS ORGANIZADOS"]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()
    exclude_lines = ["a nivel capitular", "a nivel nacional", "a nivel seccional"]

    lines = section.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)
        normalized = re.sub(r"\s+", " ", line).lower()
        if normalized and normalized not in exclude_lines:
            cleaned.append(line)

    return "\n".join(cleaned)


# ========= ANLISIS DE PRESENTACIN ==========
def evaluate_cv_presentation(pdf_path):
    """
    Eval煤a la presentaci贸n general de la hoja de vida.
    """
    text = extract_text_with_ocr(pdf_path)
    if not text:
        return {"clean_text": "", "message": "No se pudo extraer texto del PDF"}

    lines = text.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s.,;:!?-]", "", line)
        line = re.sub(r"\s+", " ", line)
        if line:
            cleaned.append(line)

    if not cleaned:
        return {"clean_text": "", "message": "El documento no contiene texto procesable"}

    return {"clean_text": "\n".join(cleaned), "message": "Texto procesado correctamente"}


# ========= CLCULOS DE INDICADORES ==========
def calculate_all_indicators(lines, position_indicators):
    """
    Calcula porcentajes de coincidencia por indicador.
    """
    total_lines = len(lines)
    if total_lines == 0:
        return {i: 0 for i in position_indicators}

    results = {}
    for indicator, keywords in position_indicators.items():
        matches = sum(any(k.lower() in line.lower() for k in keywords) for line in lines)
        results[indicator] = (matches / total_lines) * 100
    return results


def calculate_indicators_for_report(lines, position_indicators):
    """
    Calcula porcentajes y n煤mero de coincidencias por indicador.
    """
    total_lines = len(lines)
    if total_lines == 0:
        return {i: {"percentage": 0, "relevant_lines": 0} for i in position_indicators}

    results = {}
    for indicator, keywords in position_indicators.items():
        matches = sum(any(k.lower() in line.lower() for k in keywords) for line in lines)
        percentage = (matches / total_lines) * 100
        results[indicator] = {"percentage": percentage, "relevant_lines": matches}

    return results

# ============================================================
#  FUNCIONES DE EXTRACCIN DE SECCIONES
# ============================================================

def extract_profile_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'Perfil' de la hoja de vida ANEIAP.
    """
    text = extract_text_with_ocr(pdf_path)

    if not text.strip():
        print("锔 No se pudo extraer texto del PDF.")
        return ""

    start_keyword = "Perfil"
    end_keywords = ["Asistencia a eventos", "Actualizaci贸n profesional"]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        print("锔 No se encontr贸 la secci贸n 'Perfil'.")
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()
    section = re.sub(r"[^\w\s.,;:()\-]", "", section)
    section = re.sub(r"\s+", " ", section)

    return section


def extract_experience_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'EXPERIENCIA EN ANEIAP' de la hoja de vida.
    """
    text = extract_text_with_ocr(pdf_path)

    start_keyword = "EXPERIENCIA EN ANEIAP"
    end_keywords = [
        "EVENTOS ORGANIZADOS",
        "Reconocimientos individuales",
        "Reconocimientos grupales",
        "Reconocimientos"
    ]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()

    exclude_lines = [
        "a nivel capitular", "a nivel nacional", "a nivel seccional",
        "reconocimientos individuales", "reconocimientos grupales",
        "trabajo capitular", "trabajo nacional", "nacional 2024", "nacional 20212023"
    ]

    lines = section.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)
        normalized = re.sub(r"\s+", " ", line).lower()
        if (
            normalized and
            normalized not in exclude_lines and
            normalized != start_keyword.lower() and
            normalized not in [kw.lower() for kw in end_keywords]
        ):
            cleaned.append(line)

    return "\n".join(cleaned)


def extract_event_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'EVENTOS ORGANIZADOS' de la hoja de vida.
    """
    text = extract_text_with_ocr(pdf_path)
    if not text.strip():
        return ""

    start_keyword = "EVENTOS ORGANIZADOS"
    end_keywords = ["EXPERIENCIA LABORAL", "FIRMA"]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()

    exclude_lines = [
        "a nivel capitular", "a nivel nacional", "a nivel seccional",
        "reconocimientos individuales", "reconocimientos grupales",
        "trabajo capitular", "trabajo nacional"
    ]

    lines = section.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)
        normalized = re.sub(r"\s+", " ", line).lower()
        if (
            normalized and
            normalized not in exclude_lines and
            normalized != start_keyword.lower() and
            normalized not in [kw.lower() for kw in end_keywords]
        ):
            cleaned.append(line)

    return "\n".join(cleaned)


def extract_attendance_section_with_ocr(pdf_path):
    """
    Extrae la secci贸n 'ASISTENCIA A EVENTOS ANEIAP' de la hoja de vida.
    """
    text = extract_text_with_ocr(pdf_path)
    start_keyword = "ASISTENCIA A EVENTOS ANEIAP"
    end_keywords = [
        "ACTUALIZACIN PROFESIONAL", "EXPERIENCIA EN ANEIAP",
        "EVENTOS ORGANIZADOS", "RECONOCIMIENTOS"
    ]

    start_idx = text.lower().find(start_keyword.lower())
    if start_idx == -1:
        return ""

    end_idx = len(text)
    for keyword in end_keywords:
        idx = text.lower().find(keyword.lower(), start_idx)
        if idx != -1:
            end_idx = min(end_idx, idx)

    section = text[start_idx:end_idx].strip()

    exclude_lines = [
        "a nivel capitular", "a nivel nacional", "a nivel seccional",
        "capitular", "seccional", "nacional"
    ]

    lines = section.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s]", "", line)
        normalized = re.sub(r"\s+", " ", line).lower()
        if (
            normalized and
            normalized not in exclude_lines and
            normalized != start_keyword.lower() and
            normalized not in [kw.lower() for kw in end_keywords]
        ):
            cleaned.append(line)

    return "\n".join(cleaned)


# ============================================================
#  FUNCIN DE EVALUACIN DE PRESENTACIN GENERAL
# ============================================================

def evaluate_cv_presentation(pdf_path):
    """
    Eval煤a la presentaci贸n general de la hoja de vida (redacci贸n, claridad, coherencia).
    """
    text = extract_text_with_ocr(pdf_path)

    if not text.strip():
        return {"clean_text": "", "message": "No se pudo extraer el texto del PDF."}

    lines = text.split("\n")
    cleaned = []
    for line in lines:
        line = line.strip()
        line = re.sub(r"[^\w\s.,;:!?-]", "", line)
        line = re.sub(r"\s+", " ", line)
        if line:
            cleaned.append(line)

    if not cleaned:
        return {"clean_text": "", "message": "El documento no contiene texto procesable."}

    return {"clean_text": "\n".join(cleaned), "message": "Texto procesado correctamente."}


# ============================================================
#  FUNCIONES DE CLCULO DE INDICADORES
# ============================================================

def calculate_all_indicators(lines, position_indicators):
    """
    Calcula los porcentajes de coincidencia por indicador del cargo.
    """
    total_lines = len(lines)
    if total_lines == 0:
        return {indicator: 0 for indicator in position_indicators}

    results = {}
    for indicator, keywords in position_indicators.items():
        matches = sum(any(k.lower() in line.lower() for k in keywords) for line in lines)
        results[indicator] = (matches / total_lines) * 100

    return results


def calculate_indicators_for_report(lines, position_indicators):
    """
    Calcula porcentajes y cantidad de l铆neas relevantes por indicador.
    """
    total_lines = len(lines)
    if total_lines == 0:
        return {indicator: {"percentage": 0, "relevant_lines": 0} for indicator in position_indicators}

    results = {}
    for indicator, keywords in position_indicators.items():
        matches = sum(any(k.lower() in line.lower() for k in keywords) for line in lines)
        percentage = (matches / total_lines) * 100
        results[indicator] = {"percentage": percentage, "relevant_lines": matches}

    return results
